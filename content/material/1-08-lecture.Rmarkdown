---
title: "Relational Data and Joins"		
linktitle: "Lecture	8: Relational Data and Joins"
date: "2021-03-15"
start_date: "2021-03-15"
end_date: "2021-03-18"
menu:
  Material:
    parent: Lectures
    weight: 8
type: docs
toc: true
bibliography: "../../static/bib/references.bib"
csl: "../../static/bib/chicago-fullnote-bibliography-no-bib.csl"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE, 
                      warning = FALSE)
```


# Learning Outcomes

- Describe relational data.
- Use the correct R tidyverse function to manipulate data: 
  + `inner_join()`, 
  + `left_join()`, 
  + `right_join()`, 
  + `full_join()`, 
  + `semi_join()`, 
  + `anti_join()`.

# Relational Data

- Load the tidyverse

```{r, message = FALSE}
library(tidyverse)
```

- Many datasets (especially those drawn from relational databases) have more than two data frames.
- These data frames are often *logically related* where rows in one data frame correspond to, or, *have a relation to*, rows in another data frame.
- Large Relational Databases are typically designed (by data engineers) to achieve some level of "normalization" 
- The goal of normalization is to design the set of tables (data frames) to capture all of the data while achieving a balance across:
  + storage size, 
  + query speed, 
  + ease of maintenance by users, and 
  + minimal delays for distributed operations with multiple users. 
- Table design strives to:
  + reduce data duplication (which increases storage and the potential for errors), and
  + enable multiple users to update their tables without interference from other users.
- A principle of normalization is to *limit tables to a single purpose.*
- As R users, we might say, a table (dataframe) describes one type of (observational or experimental) unit, with all the observations for each *variable associated with that unit and only that unit*. 
- In modern databases, you may run into tables containing blob objects such as pictures, figures, or movies
  + You may need to work with the database administrator to get only the data you need into R.

## Example: The Lahman Data Set has Multiple Tables 

- Consider the tables/data frames in the [lahman](https://github.com/cdalzell/Lahman) package.

```{r eval = FALSE}
install.packages("Lahman")
```

```{r}
library(Lahman)
```
- Use the `data(package = "package-name")` to see the data sets in a package
```{r}
data(package = "Lahman")
```

### Each Table has One Purpose: To Describe One Type of Unit
```{r} 

# Let's turn these 5 dataframes into tibbles while we're here:
People <- as_tibble(Lahman::People)
Teams <- as_tibble(Lahman::Teams)
Fielding <- as_tibble(Lahman::Fielding)
Pitching <- as_tibble(Lahman::Pitching)
Batting <- as_tibble(Lahman::Batting)


# `People`: Player names, DOB, and biographical info.
head(People)

# `Teams`: Yearly statistics and standings for teams.
head(Teams)

# `Fielding`: Fielding stats
head(Fielding)

# `Pitching`: Pitching stats
head(Pitching)

# `Batting`: Batting stats
head(Batting)


```


### These Tables are Logically Connected
- Fields in one table "relate" to fields in one or more other tables

![](/img/lahman_viz.png) 

- For Lahman:
  + `Batting`, `Fielding`, and `Pitching` connect to `People` via a single variable, `PeopleID`.
  + `Batting`, `Fielding`, and `Pitching` connect to `Teams` through the `YearID`, `TeamID` and `lgID` variables.
    
# We Define Variables as "Keys" to Identify Rows and to Make Logical Connections Between Tables.

- Every Table should have a **Primary key** to uniquely identify (differentiate) its rows. 
  + Keys must be unique in their own table, i,e., only refer to one instance of an item. 
  + Good Data engineers create keys with no intrinsic meaning other than being a unique identifier. 
  + Some tables may use a *combined key* based on multiple columns, e.g., year, month, day together.
  + The primary key from one table may appear many times in other tables. 

- *Example*: `People$playerID` is a primary key for `People` because it uniquely identifies the rows in `People`.
- To check if you have identified the Primary Key fields, use `group_by(primary_key_fields)` and `count()` to see if there are multiple rows for any group.
- If any group has more than one row, the fields are insufficient to serve as a primary key
```{r}
# type is Not a Primary Key
People %>%
  group_by(nameLast) %>%
  count() %>%
  filter(n > 1)

# This is a primary key
People %>%
  group_by(playerID) %>%
  count() %>%
  filter(n > 1)

```
- A primary key can also serve as a foreign key when present in another table.
- A **Foreign key** is used to identify rows in another (child) table.
- *Example*: In `Pitching`, `$playerID` is a foreign key for the other table `People` because it uniquely identifies rows in `People`. 
- There can be multiple rows with the same foreign key in a table, e.g., `playerID` in `Pitching`, so `Pitching$playerID` is *not* a primary key in Pitching

```{r}
Pitching %>% 
  group_by(playerID) %>%
  count() %>%
  filter(n > 1)
```


# Join Functions in the dplyr Package

- Getting data from two (or more) tables requires using the primary keys and foreign keys to logically connect the tables.
- These "connections" are called **joins**
- The dplyr package has functions to connect or join tables so you can work with their data
- The dplyr package supports seven types of joins: 
  + Four types of **mutating joins**, 
  + Two types of **filtering joins**, and 
  + A **nesting join**.
- Many sources refer to the first table in a join function argument list as the `x` table or the left table or the "parent" table and second table in the argument as the `y` table or the right table or the "child" table 
- The primary key fields for the `y`/right/child table must be able to be matched to fields in the `x`/left/parent table which can serve as a foreign key.

# Mutating Joins: Inner, Left, Right, Full
![](https://d33wubrfki0l68.cloudfront.net/aeab386461820b029b7e7606ccff1286f623bae1/ef0d4/diagrams/join-venn.png)
- Mutating Joins affect the rows and columns of either the `x` or `y` table
- `inner_join()`: returns *all rows from x where there are matching values in y*, and *all columns from x and y*. 
  + If there are multiple matches between x and y, all combination of the matches are returned.
  + Rows that do not match are not returned
- `left_join(): `returns *all rows from x*, and *all columns from x and y*. 
  + Rows in x with no match in y are returned but will have `NA` values in the new columns. 
  + If there are multiple matches between `x` and `y`, all combinations of the matches are returned.
- `right_join()`: returns *all rows from y*, and *all columns from x and y*.
  + Rows in `y` with no match in `x` will have `NA` values in the new columns. 
    + If there are multiple matches between `x` and `y`, all combinations of the matches are returned.
- `full_join()`: returns *all rows and all columns from both x and y*. 
  + Where there are not matching values, returns `NA` for the missing values.
  
  
```{r}
x <- tribble(
  ~key, ~val_x,
     1, "x1",
     2, "x2",
     3, "x3"
)
x

y <- tribble(
  ~key, ~val_y,
     1, "y1",
     2, "y2",
     4, "y4"
)
y
```
  

## `inner_join(x, y)` 
- This is the simplest join to add 
- Matches the rows of `x` with rows of `y` *only when their keys are equal*.
![](https://github.com/gadenbuie/tidyexplain/raw/master/images/inner-join.gif)  
![](/img/join-inner.png)

```{r, inner_join}
inner_join(x, y, by = "key")
```

- Keeps all rows that appear in *both* data frames.
- if the key is missing on either the left or right side, that row will be dropped from the join. 


### Exercise: 
- Select all batting stats for players who were born in the 1980s.

```{r}

People %>% 
  filter(between(birthYear, 1980, 1989)) %>% 
  nrow()

nrow(Batting)

People %>% 
  filter(between(birthYear, 1980, 1989)) %>% 
  inner_join(Batting, by = "playerID") %>% 
  nrow()
```


## Outer Joins: Left, Right, Full

- Outer Joins keep all rows that appear in *at least one* data frame and add columns from the other table for those rows.

![](/img/join-outer.png)

### `left_join(x, y)` 
![](https://github.com/gadenbuie/tidyexplain/raw/master/images/left-join.gif)

- Keeps all rows of `x` and adds columns from `y`. 
- Puts in `NA` in the new `y` columns if no match.
- By far the *most common* join
- Always use a left join unless you have a good reason not to.

```{r}
left_join(x, y, by = "key")
```
   
### `right_join(x, y)` 
![](https://github.com/gadenbuie/tidyexplain/raw/master/images/right-join.gif)
- Keeps all rows of `y`and adds columns from `x`. 
- Puts in `NA` in `x` columns if no match.

```{r}
right_join(x, y, by = "key")
```
- Note what happens when you switch the type of join and the data frame
```{r}
left_join(y, x, by = "key")
```
- You have flexibility to choose the order you are doing the joins and the type of joins to get the results you want from your workflow.

### `full_join(x, y)` 
![](https://github.com/gadenbuie/tidyexplain/raw/master/images/full-join.gif)
- Keeps all rows of both and adds columns from `y` to `x`.
- Puts in `NA` wherever there is no match
- Can cause a lot of extra rows and columns with `NAs` if not careful
- Only use when absolutely necessary and then only after you have selected the desired variables and filtered the desired rows.

```{r}
full_join(x, y, by = "key")
```
    

### Exercise: 
- Add the team name to the `Batting` data frame.
```{r}
names(Batting)
names(Teams)

Batting %>% 
  left_join(Teams, by = "teamID") %>%
  select(name, everything())
```

- list the first name, last name, and team name for every player who played in 2018
```{r}
Batting %>% 
  filter(yearID == 2018) %>% 
  left_join(People, by = "playerID") %>% 
  left_join(Teams, by = "teamID") %>% 
  select(nameFirst, nameLast, name) %>% 
  distinct()
```

 

## Duplicate Keys
- One would not expect to have rows with duplicate primary keys in a table from a relational database (most enforce no duplicates on the primary key fields)
- However, data from sources without rules enforcing key uniqueness often have them.
- If you have duplicate keys the `x` table, then during a left join with a `y` where there is no duplication, the rows of `y` are copied multiple times into the new `x` data frame.

![](/img/join-one-to-many.png)
    
- This can be useful when you want to add additional information (rows) to `x` as there can be a one-to-many relationship.
- In a sense the "original" `x` key was really a foreign key with respect to the join as it did not uniquely identify the rows in `x` but was a primary key for `y`.

```{r}
x_mult <- tribble(~key, ~val_x,
                  ##--  ------
                  1,    "x1",
                  2,    "x2",
                  2,    "x3",
                  1,    "x4")
y

x_mult %>% 
  left_join(y, by = "key")

```
    

- If you have duplicate keys in both (usually a mistake), then you get *every possible combination* of the values in x and y at the key values where there are duplications.

![](/img/join-many-to-many.png)
    
```{r}
x_mult
y_mult <- tribble(~key, ~val_y,
                  ##--  ------
                  1,    "y1",
                  2,    "y2",
                  2,    "y3",
                  1,    "y4")

left_join(x_mult, y_mult, by = "key")
```

# Filtering Joins Filter Rows in the Left (`x`) Data Frame:
- They do not add columns; they just filter the rows of `x` based on values in `y`
- `semi_join()`: returns *all rows from x where there are matching key values in y*, keeping *just columns from x*. 
  + Filters out rows in `x` that do *not* match anything in `y`. 

- A semi-join is not the same as an inner join 
  + an inner join will return one row of `x` for each matching row of `y`, (potentially adding  multiple rows) whereas
  + a semi-join will never duplicate rows of `x`. 

## `semi_join(x, y)` 

![](https://github.com/gadenbuie/tidyexplain/raw/master/images/semi-join.gif)  
- *Keeps* all of the rows in `x` that have a match in `y` (but doesn't add the variables of `y` to `x`).
  
```{r}
semi_join(x, y, by = "key")
```
    
## `anti_join()` 

![](https://github.com/gadenbuie/tidyexplain/raw/master/images/anti-join.gif)

- `anti_join()`: returns *all rows from x where there are not matching key values in y*, keeping *just columns from x*.
  + Filters out rows in x that do match anything in y (the rows with no join).

- *Drops* all of the rows in `x` that *do not* have a match in `y` (but doesn't add the variables of `y` to `x`).

In human speak, *what's in x but not y?*
  

```{r}
anti_join(x, y, by = "key")
```
  
### Exercise: 
- Find the 10 players with the highest number of strikeouts (`SO`) from the `Batting` table and assign to a new data frame. 
- Join the appropriate data frames to select all players from those 10 days.
  
```{r}
ten_worst <- Batting %>%
  group_by(playerID) %>%
  summarize(count_strikeout = sum(SO, na.rm = TRUE)) %>%
  slice_max(count_strikeout, n =10) 

People %>% 
  semi_join(ten_worst)

#note, you can do this same operation with filtering too:
    ten_worst_vector <- ten_worst %>% 
      pull(playerID)
    
    People %>% 
      filter(playerID %in% ten_worst_vector)
```
  
# Other Key Names

- If the primary and foreign keys names do not match, you need to specify the matching  names in a vector
- Example: `left_join(x, y, by = c("a" = "b"))`, where `a` is the key in `x` and `b` is the key in `y`.
- Here we join by single keys with different names in the `x` and `y` data frames
```{r}
library(nycflights13)
flights %>% 
  left_join(airports, by = c("origin" = "faa")) %>% 
  head()
```
    
- If you have multiple variables acting as a combined key, specify the `by` argument 
  as a vector.
- If they have the same name, you can drop the `=` argument
- The `,` serve as an "AND" operator

```{r}

Fielding %>% 
left_join(Teams, by = c("yearID", "lgID", "teamID")) %>% 
  head()
```
 
- You can specify both multiple variables and with different names if necessary
- You cannot specify one key from `x` to have two different values in `y` - there is no "OR" operation; you have to do two joins.
  
# Set operations
![](https://github.com/gadenbuie/tidyexplain/raw/master/images/static/png/original-dfs-set-ops.png){width = 50%}

```{r}
x <- tribble(
  ~key, ~val,
     1, "a",
     1, "b",
     2, "a"
)

y <- tribble(
  ~key, ~val,
     1, "a",
     2, "b",
)
```

Set operations are occasionally useful when you want to break a single complex filter into simpler pieces. All these operations work with a complete row, comparing the values of every variable. These expect the x and y inputs to have the same variables, and treat the observations like sets.



## Union
All unique rows from x and y.
![](https://github.com/gadenbuie/tidyexplain/raw/master/images/union-rev.gif)


```{r}
union(y, x)
```

## intersect
Common rows in both x and y, keeping just unique rows.

![](https://github.com/gadenbuie/tidyexplain/raw/master/images/intersect.gif)

```{r}
intersect(x, y)
```
because table x had a dupicated row, it was removed. 

## setdiff 
All rows from x which are not also rows in y, keeping just unique rows.

![](https://github.com/gadenbuie/tidyexplain/raw/master/images/setdiff.gif)
```{r}
#what is in x but not in y?
setdiff(x, y)
```

![](https://github.com/gadenbuie/tidyexplain/raw/master/images/setdiff-rev.gif)
```{r}
#what is in y but not in x?
setdiff(y, x)
```



# Appending Data
Sometimes you want to add rows to your data instead of adding new columns. This
happens a lot when you have new data coming in daily or weekly. To handle this
data, we will use the `bind_rows()` function. To see how this works, let's look
at some play data about plant growth. In this situation, let's say we have a
sensor sending us new readings daily. How could we combine these data into one
tibble?

```{r}
march03 <- tibble::tribble(
             ~plant_id, ~treatment,     ~height, ~temperature,   ~humidity,
               "k3jak",  "control", 1.234156382,          82L, 0.257529979,
               "df33l",  "control", 1.380212809,          83L, 0.058794941,
               "l122j",  "treated", 1.526392762,          89L, 0.297541584,
               "3kssj",  "treated", 1.673373933,          80L, 0.881550707
             )


march04 <- tibble::tribble(
             ~plant_id, ~treatment,     ~height, ~temperature,   ~humidity,
               "k3jak",  "control", 1.660054506,          92L, 0.474884172,
               "df33l",  "control",  1.87979144,          83L, 0.769558459,
               "l122j",  "treated", 1.686950799,          86L, 0.228663423,
               "3kssj",  "treated", 2.032178067,          87L,   0.0340041
             )


march05 <- tibble::tribble(
             ~plant_id, ~treatment,     ~height, ~temperature,   ~humidity,
               "k3jak",  "control", 1.933533759,          89L, 0.975123013,
               "df33l",  "control", 1.990040605,          97L, 0.724627173,
               "l122j",  "treated", 1.996540851,          94L, 0.490475035,
               "3kssj",  "treated", 2.116540208,          93L, 0.169962639
             )
```

```{r}
march03 <- march03 %>% 
  mutate(date = lubridate::mdy("03/03/2021"))
march04 <- march04 %>% 
  mutate(date = lubridate::mdy("03/04/2021"))
march05 <- march05 %>% 
  mutate(date = lubridate::mdy("03/05/2021"))

plants <- march03 %>% 
  bind_rows(march04) %>% 
  bind_rows(march05)

#alternatively, we could do a "subquery" on each of these dataframes.. 

march03 %>% 
  mutate(date = lubridate::mdy("03/03/2021")) %>% 
  bind_rows(mutate(march04, date = lubridate::mdy("03/04/2021"))) %>% 
  bind_rows(mutate(march05, date = lubridate::mdy("03/05/2021")))

```
In the example above, why do we want to `bind_rows()` instead of a join? 


Bind rows matches column names, so if there are missing columns, they will be filled with `NA` in the newly added rows like the following. 
```{r}
a <- tibble(x = 1:3, y = c(4,5,NA)) 
a
b <- tibble(y = 1:4, z = runif(4))
b

a %>% 
  bind_rows(b)
```


# References
  + Chapter 13 of [RDS](https://r4ds.had.co.nz/).
  + [Data Transformation Cheatsheet](https://github.com/rstudio/cheatsheets/blob/master/data-transformation.pdf)
  + [TidyExplain GIFs](https://github.com/gadenbuie/tidyexplain)

# Appendix on dbplyr
While we won't dicuss this in the lecture, this is an important reference you
will likely want for working with databases in R. Feel free to run through these
exercises on your own time.

- **References**
  + [Introduction to dbplyr](https://cran.r-project.org/web/packages/dbplyr/vignettes/dbplyr.html)

**Motivation**

- R typically works with all of the data accessible in the working memory of your computer. The more memory the larger the data set you can work with.
- In the era of big data there are many data set too large to fit into memory.
- The **dbplyr package allows R to work with "remote" on-disk data stored in a database**. 
- This is particularly useful in two scenarios:
  + Your data is already in a database on your computer or cloud drive as opposed to a .csv or rdata  file.
  + You have so much data it does not all fit into memory simultaneously and you need to use some external storage engine.
  + If your data fits in memory, there is no advantage to putting it in a database: it will only be slower and more frustrating.

## The dbplyr package

- The dbplyr functions provide a common interface to a back-end package (DBI) so you can use dplyr functions with many different databases using the same code. 
- You need to install a specific back-end for the database type you want to connect to.
- Five commonly used back-ends are:
  + **RSQLite** embeds a SQLite database.
  + **RMariaDB** connects to MySQL and MariaDB
  + **RPostgres** connects to Postgres and Redshift.
  + **odbc** connects to many commercial databases via the *open database connectivity protocol* (ODBC).
  + **bigrquery** connects to Google’s BigQuery.

## Structured Query Language (SQL)
- [SQL](https://en.wikipedia.org/wiki/SQL) is a language used for many years to interact with data sets stored in relational database management systems (RDBMS).
- Common actions include: select, insert, update, or delete individual records as well as the different kinds of joins across the tables in the RDBMS 
- The dbplyr package implements the most common actions people do with SQL (but SQL can do more).
- As the database back-end for dplyr, *dbplyr automatically converts dplyr code into SQL*

## Example using RSQLite with a soccer data set 
- We'll use a soccer dataset with multiple tables to demonstrate how to use dbplyr (instead of SQL) syntax when interacting with a database. 

## Setup the Data and Packages
Download and unzip the database here: [<i class="fas fa-database"></i> `soccer.zip`](/data/soccer.zip)  
  
- We'll use the dbplyr package to interact with databases.
- dbplyr is part of the tidyverse but is *not loaded as a core package* with `library(tidyverse)` so you have to install using the console and load it separately

```{r, eval = FALSE}
install.packages("dbplyr")
```

```{r, message = FALSE}
library(tidyverse)
library(dbplyr)
```


- You'll also need to install and load the RSQLite package. 
  
```{r, eval = FALSE}
install.packages("RSQLite")
```

```{r}
library(RSQLite)
```

## Two Steps to Get Started: Connect and Create Names   
1.  Use `dbConnect()` to open a connection to the database. 
- Assign the output to a variable to tell R where the database is (you might need to change the path).

```{r}
con <- dbConnect(drv = SQLite(), dbname = here::here("static", "data","soccer.sqlite"))
```

- Use `dbListTables()` to list the data frames available in the connection you just created.
```{r}
dbListTables(con)
```
    
2. Use the table function,`tbl()`, to create reference names (variables) for the tables in `con`.
- Create one for each table of interest
- Note these are *not* dataframes, but are lists

```{r}
Team_db    <- tbl(con, "Team")
Team_at_db <- tbl(con, "Team_Attributes")
Country_db <- tbl(con, "Country")
League_db  <- tbl(con, "League")
Match_db   <- tbl(con, "Match")
```
    
## Use dplyr to Manipulate the Data
- We can now use dplyr to interact with these data frames *almost* like they were actually in memory (with some limitations).

```{r, eval = FALSE}
head(Country_db)
head(Match_db)
Match_db %>%
  select(id:away_team_goal)

names(Match_db) ## gives you the names of the list
Match_db$ops$vars
```
    
- Select the variables you want and/or the observations you want,then use `collect()` to convert into a data frame in memory 
- Then you have access to all of the functionality of R, e.g., `pivot_longer()` and `pivot_wider()` (which will only work on in-memory data frames).
  
```{r, collect, error = TRUE}
# Produces an error
Match_db %>%
  pivot_longer(cols = contains("player"),
               names_to = "Player",
               values_to = "Present")

Match <- Match_db %>%
  select(id:away_team_goal) %>%
  collect() 
  
Team <- Team_db %>%
  collect() 
  
Country <-  Country_db %>%
  collect() 
  
```
    
- The following will return a data frame with the home country for each team.
    
```{r}
Match %>%
  select(country_id, home_team_api_id, away_team_api_id) %>%
  pivot_longer(-country_id, names_to = "home_away", values_to = "team_api_id") %>% 
  select(-home_away) %>%
  distinct() %>% 
  left_join(Team, by = "team_api_id") %>%  # get the team info
  left_join(Country, by = c("country_id" = "id")) %>%  # get Country name
  select(team_long_name, team_short_name, name) %>%
  rename(country_name = name) %>% 
  arrange(team_long_name) %>% 
  head()
```
    
### Exercise: 
- Find the league_id for the `England Premier League`
- Extract all matches for the `England Premier League` for each day in the `"2010/2011"` season into a new data set.
- Calculate the mean of the difference between home team goals and away team goals for each day in the  season. 
  + You'll need to separate date and time. 
  + You'll also need to use `parse_date()` before you plot.
- Plot this proportion against time.  

```{r}
League <- League_db %>% 
  collect()
  
head(League)

League %>% 
  filter(name =="England Premier League")

subMatch <- Match_db %>%
  select(league_id, season, date, home_team_goal, away_team_goal) %>%
  filter(league_id == 1729, season == "2010/2011") %>%
  collect()
  

ave_diff <- subMatch %>%
  separate(col = "date", into = c("date", "time"), sep = " ") %>%
  select(-time) %>%
  group_by(date) %>%
  summarize(mean_diff = mean(home_team_goal - away_team_goal)) %>%
  mutate(date = parse_date(x = date, format = "%Y-%m-%d"))
  
```

- Your plot should look like this:
```{r}
ggplot(data = ave_diff, mapping = aes(x = date, y = mean_diff)) +
  geom_line() +
  xlab("Date") +
  ylab("Mean Difference") +
  theme_bw()
```
  
You can also visualize your database relationship with the `dm` package. While the primary and foreign keys are generally recognized, in our case we need to add them manually. You can find more information about the `dm` package [here](https://krlmlr.github.io/dm/)
```{r eval = FALSE}
install.packages("dm")
```

```{r}
library(dm)
dm <- dm_from_src(con, learn_keys = FALSE) %>% 
  dm_add_pk(Country, id) %>%
  dm_add_pk(League, id) %>%
  dm_add_pk(Team, team_api_id) %>%
  dm_add_pk(Team_Attributes, id) %>% 
  dm_add_pk(Match, id) %>%
  dm_add_pk(Player, id) %>%
  dm_add_pk(Player_Attributes, id) %>%
  dm_add_fk(League, country_id, Country) %>%
  dm_add_fk(Match, country_id, Country) %>%
  dm_add_fk(Match, home_team_api_id, Team) %>%
  dm_add_fk(Match, away_team_api_id, Team) %>%
  dm_add_fk(Match, league_id, League) %>% 
  dm_add_fk(Player_Attributes, id, Player) %>%
  dm_add_fk(Team_Attributes, team_fifa_api_id, Team) %>% 
  dm_add_fk(Team_Attributes, team_api_id, Team)

dm %>%
  dm_draw()
```







